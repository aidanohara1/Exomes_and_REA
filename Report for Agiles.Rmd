---
title: "Report for A Giles"
author: "Aidan O'Hara"
date: "2023-03-31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(Rmisc) 
library(dplyr)
library(tidyr)
library(gmodels)
library(ggplot2)
library(nnet)
library(lmtest)

# read in
AGiles <- read.csv("AGiles.csv")
AGiles_OG <- read.csv("AGiles_originalOnly.csv")
# original reports are already isolated in Agiles_OG

# AGiles <- read.csv("~/Desktop/ma676_featureengineering_automl-Ashleycc1/AGiles.csv")
# AGiles_OG <- read.csv("~/Desktop/ma676_featureengineering_automl-Ashleycc1/AGiles_originalOnly.csv")

AGiles <- rename(AGiles, 
       abcBuckets = `ABC.REA.buckets`,
       sex = `Sex..reported.at.birth.`,
       age = `Age.Group`,
       indication = `Indication.Diagnostic.Rate`,
       reanalyzed = Reanalyed)

AGiles_OG <- rename(AGiles_OG, 
       abcBuckets = `ABC.REA.buckets`,
       sex = `Sex..reported.at.birth.`,
       age = `Age.Group`,
       indication = `Indication.Diagnostic.Rate`,
       reanalyzed = Reanalyed)



AGiles$`Report.Outcome`[AGiles$`Report.Outcome` == "positive"] <- "Positive"
AGiles$`Initiator.of.reanalysis`[AGiles$`Initiator.of.reanalysis` == "Family Studies"] <- "Family studies"

# factorize report outcome
AGiles_OG <- mutate(AGiles_OG, classification = ifelse(`Report.Outcome`=="Positive",1,
                                                       ifelse(`Report.Outcome`=="Uncertain",0,-1)))
# factorize report outcome
AGiles <- mutate(AGiles, classification = ifelse(`Report.Outcome`=="Positive",1,
                                                       ifelse(`Report.Outcome`=="Uncertain",0,-1)))

# factorize report outcome again
AGiles_OG <- mutate(AGiles_OG, reclassification = ifelse(`Report.Outcome`=="Positive",1,0))
# factorize report outcome again
AGiles <- mutate(AGiles, reclassification = ifelse(`Report.Outcome`=="Negative",0,1))

latestAgilesGG <- group_by(AGiles, `New.study.ID`) %>%
  slice(which.max(as.Date(`Report.Date`, '%M/%Y'))) %>%
  mutate(binReanaz = ifelse(`Original.Latest` != "Original", 1,0))


AGiles <- AGiles %>% mutate(across(c(reanalyzed,
                                     Reclassified,
                                     Original.Latest,
                                     Report.Outcome,
                                     Initiator.of.reanalysis,
                                     Evidence.for.reclassification,
                                     Default.REA.buckets,
                                     abcBuckets,
                                     sex,
                                     classification,
                                     reclassification),
                                   factor))

AGiles_OG <- AGiles_OG %>% mutate(across(c(reanalyzed,
                                           Reclassified,
                                           Original.Latest,
                                           Report.Outcome,
                                           Initiator.of.reanalysis,
                                           Evidence.for.reclassification,
                                           Default.REA.buckets,
                                           abcBuckets,
                                           sex,
                                           classification,
                                           reclassification),
                                         factor))

betterLevels <- c("A", "B", "C", "D", "E", "F", "G", "H")
age_levels <- c("Fetal", "<1", "1-5", "6-10", "11-18", "19-35", "36-50", "51+")


AGiles$age = factor(x = AGiles$age, levels = age_levels, ordered = T)
AGiles_OG$age = factor(x = AGiles_OG$age, levels = age_levels, ordered = T)
# 
# levels(AGiles$age) <- betterLevels
# levels(AGiles_OG$age) <- betterLevels


# remove repeated observations by keeping only the newest log
latestAgiles <- group_by(AGiles, `New.study.ID`) %>%
  slice(which.max(as.Date(`Report.Date`, '%M/%Y'))) %>%
  mutate(binReanaz = ifelse(`Original.Latest` != "Original", 1,0))

### Making two separate samples for models that talk about reclassification

# one sample will have every reanalysis event, 
justReanaz <- AGiles %>% filter(reanalyzed == 1)
# the other sample will have one reanalysis event, per study id, randomly selected
set.seed(800)

myList <- split(justReanaz, justReanaz$`New.study.ID`)

uniqueReanaz <- data.table::rbindlist(lapply(myList, 
                                             function(x) if(nrow(x) > 1) x[sample(nrow(x), 1), ] else x))


# Sample of 
# REA ABC buckets with confounders of  binary is positive vs is uncertain (negatives removed)
#  cases with reported alterations

posUncertain <- AGiles %>% filter(Reclassified == 1 & classification != -1)

myList2 <- split(posUncertain, posUncertain$`New.study.ID`)

uniqueUncertain <- data.table::rbindlist(lapply(myList2, 
                                             function(x) if(nrow(x) > 1) x[sample(nrow(x), 1), ] else x))

# stinky outlier, little baby
posUncertain <- filter(posUncertain, `New.study.ID` != "AMB_00206")
uniqueUncertain <- filter(uniqueUncertain, `New.study.ID` != "AMB_00206")

# Just reclassifications
# check for outliers
justReclass <- AGiles %>% filter(Reclassified == 1)

myList3 <- split(justReclass, justReclass$`New.study.ID`)
uniqueReclass <- data.table::rbindlist(lapply(myList3, 
                                             function(x) if(nrow(x) > 1) x[sample(nrow(x), 1), ] else x))


# Bust this out if you want to remove Original logs of exomes that have been reanalyzed
#   BUT you want to keep the multiple reanalysis logs

# # tally of id entries per id, helper
# idEntries <- group_by(AGiles, `New.study.ID`) %>%
#   tally()
# 
# # the agiles Ill use for analysis, 
# # most important note is the ommision of Orgianal reports about exomes that have been reanalyzed.
# # keeping multiple reanalysis still... There are tradeoffs
# omitAgiles <- inner_join(AGiles, idEntries, by = "New.study.ID") %>%
#   filter(!(n>1 & `Original.Latest` == "Original"))



```

```{r reclassificationEDAPlots, include=FALSE}
### RECLASSSIFICATION plot ###
reclassMeans <- group_by(latestAgilesGG, abcBuckets) %>%
  dplyr::summarise(meanReclassification = mean(Reclassified),
            uci_perGroup = CI(Reclassified)['lower'],
            lci_perGroup = CI(Reclassified)['upper']) %>%
  arrange(abcBuckets)

reanazMeans <- group_by(latestAgilesGG, abcBuckets) %>%
  dplyr::summarise(meanReanaz = mean(reanalyzed),
                   uci_perGroup = CI(reanalyzed)['lower'],
                   lci_perGroup = CI(reanalyzed)['upper']) %>%
  arrange(abcBuckets)

classMeans <- group_by(latestAgilesGG, abcBuckets) %>%
  dplyr::summarise(meanClassification = mean(classification),
                   uci_perGroup = CI(classification)['lower'],
                   lci_perGroup = CI(classification)['upper']) %>%
  arrange(abcBuckets)

latClassMeans <- group_by(latestAgilesGG, abcBuckets) %>%
  dplyr::summarise(meanClassification = mean(classification),
                   uci_perGroup = CI(classification)['lower'],
                   lci_perGroup = CI(classification)['upper']) %>%
  arrange(abcBuckets)


reclassGG <- ggplot(reclassMeans) +
  geom_bar( aes(x=abcBuckets, y=meanReclassification), stat = "identity", alpha = 0.5) +
  geom_errorbar( aes(x=abcBuckets, ymin=lci_perGroup, ymax=uci_perGroup, color = abcBuckets), alpha=0.9, size=1)+
  coord_flip()+
  ylab("mean reclass") +
  theme_dark()

reanazGG <- ggplot(reanazMeans) +
  geom_bar( aes(x=abcBuckets, y=meanReanaz), stat = "identity", alpha = 0.5) +
  geom_errorbar( aes(x=abcBuckets, ymin=lci_perGroup, ymax=uci_perGroup, color = abcBuckets), alpha=0.9, size=1)+
  coord_flip() +
  ylab( "mean R2") +
  theme_dark()

classGG <- ggplot(classMeans) +
  geom_bar( aes(x=abcBuckets, y=meanClassification), stat = "identity", alpha = 0.05) +
  geom_errorbar( aes(x=abcBuckets, ymin=lci_perGroup, ymax=uci_perGroup, color = abcBuckets), alpha=0.9, size=1)+
  ggtitle("Cumulative classifications") +
  coord_flip()+
  theme_dark()

latClassGG <- ggplot(latClassMeans) +
  geom_bar( aes(x=abcBuckets, y=meanClassification), stat = "identity", alpha = 0.05) +
  geom_errorbar( aes(x=abcBuckets, ymin=lci_perGroup, ymax=uci_perGroup, color = abcBuckets), alpha=0.9, size=1)+
  ggtitle("Up to Date classifications") +
  coord_flip()+
  theme_dark()

reclassGG
reanazGG
classGG
latClassGG
```

```{r, include=FALSE}
# summary tables
newOg <- AGiles_OG %>% group_by(abcBuckets, classification) %>%
  summarise(n = n()) %>%
  group_by(abcBuckets) %>% mutate(prob = n / sum(n))

#View(newOg)

newLatest <- latestAgiles %>% group_by(abcBuckets, classification) %>%
  summarise(n = n()) %>%
  group_by(abcBuckets) %>% mutate(prob = n / sum(n)) 

#View(newLatest)


```

```{r modelexplore1, include=FALSE}
# Does the distribution of original exome outcomes differ by REA? #
originals <- AGiles_OG

#age_levels <- c("Fetal", "<1", "1-5", "6-10", "11-18", "19-35", "36-50", "51+")

#originals <- originals %>% mutate(classFact = as.factor(classification),
                                  # abcFact = as.factor(abcBuckets),
                                  # sexFact = as.factor(sex),
                                  # ageFact = as.factor(age))
# 
# ogClassification <- multinom(data = originals, 
#                              formula = classification ~ abcBuckets + age + sex) # Angwer


# test <- predict(ogClassification, data = originals, type = "prob")
# ogTrain <- data.frame(abcFact = unique(originals$abcFact))
# 
# # test2 <- predict(ogClassification, originals[!duplicated(originals),])
# 
# uniqueCombs <- originals[!duplicated(originals),] %>% mutate(
#   modelPred = test2)

# Problem, the model is not making any kind of accurate prediction
```

```{r modelexplore2, include=FALSE}

classModel <- glm(data = originals,
                  formula = reclassification ~ abcBuckets + sex + age, family = "binomial")


```

```{r modelexplore3, include=FALSE}
oneReclass <- glm(data = latestAgiles, formula = reanalyzed ~ abcBuckets, family = binomial)

oneReclassConfound <- glm(data = latestAgiles, formula = reanalyzed ~ abcBuckets + age + sex + indication,
                          family = binomial)

#make a hit table
# 
# oneReclass2 <- glm(data = latest, formula = Reanalyed ~ A + B + C + A:B + B:C + A:C + A:B:C, family = binomial)
# 
# oneReclass3 <- glm(data = latest, formula = Reanalyed ~ A + B + C, family = binomial)

anova(oneReclass, test = 'Chisq')
anova(oneReclassConfound, test = 'Chisq')

CrossTable(latestAgiles$abcBuckets, latestAgiles$reanalyzed, 
           digits = 2,
           prop.r = T, # row proportion
           prop.c = F, # column proportion
           prop.t = F, # table proportion
           prop.chisq = T, # chi-squared contribution
           expected = T,
           resid = T)


```

```{r gilesmodel1, include=FALSE}
# REA Default buckets with confounders age/sex/(?indication) by:
# Binary: positive vs is not positive (uncertain and negatives together)
#                 -at original classification
#                 -at current classification

originals <- mutate(originals, classification = ifelse(`Report.Outcome` == "Positive", 1,
                                                       ifelse(`Report.Outcome` == "Uncertain", 0,
                                                              ifelse(`Report.Outcome` == "Negative", 0, NA))))


model1.1 <- glm(data = originals,formula = classification ~ Default.REA.buckets + sex + age + indication,family = binomial)
model1.1.red <- glm(data = originals,formula = classification ~ sex + age + indication,family = binomial)


model1.2 <- glm(data = latestAgiles,formula = classification ~ Default.REA.buckets + sex + age + indication,family = binomial)
model1.2.red <- glm(data = latestAgiles,formula = classification ~ sex + age + indication,family = binomial)

nameOfOutput.11 <- "pos vs not pos at original classification, defaults"
nameOfOutput.12 <- "pos vs not pos at latest classification, defaults"

```

```{r gilesmodel2, include=FALSE}
#Binary: was reanalyzed vs was not reanalyzed
model2 <- glm(data = latestAgiles ,formula = reanalyzed ~ Default.REA.buckets + sex + age + indication,family = binomial)
model2.red <- glm(data = latestAgiles ,formula = reanalyzed ~ sex + age + indication,family = binomial)

nameOfOutput.2 <- "R2 or not with latest reports, default"

```

```{r reclassmodel2, include=FALSE}
#Binary: was reclassified vs was not reclassified
reclass21 <- glm(data = justReanaz, 
                 formula = Reclassified ~ `Default.REA.buckets` + age + sex + indication,
                 family = binomial)

reclass22 <- glm(data = uniqueReanaz, 
                 formula = Reclassified ~ `Default.REA.buckets` + age + sex + indication,
                 family = binomial)

reclass21.red <- glm(data = justReanaz, 
                     formula = Reclassified ~ age + sex + indication,
                     family = binomial)

reclass22.red <- glm(data = uniqueReanaz, 
                     formula = Reclassified ~ age + sex + indication,
                     family = binomial)
nameOfOutput.21 <- "reclass vs not with all R2, defaults"
nameOfOutput.22 <- "reclass vs not with sampled R2, defaults"

```

```{r gilesmodel3, include=FALSE}
# REA ABC buckets with confounders age/sex/(?indication) by:
# Binary: positive vs is not positive (uncertain and negatives together)
#                -at original classification
#                -at current classification

model3.1 <- glm(data = originals, formula = classification ~ abcBuckets + sex + age + indication, family = binomial)

model3.2 <- glm(data = latestAgiles, formula = classification ~ abcBuckets + sex + age + indication, family = binomial)

model3.1.red <- glm(data = originals, formula = classification ~ sex + age + indication, family = binomial)

model3.2.red <- glm(data = latestAgiles, formula = classification ~ sex + age + indication, family = binomial)

nameOfOutput.31 <- "pos vs not pos at original classification, abc"
nameOfOutput.32 <- "pos vs not pos at latest classification, abc"
```

```{r gilesmodel4, include=FALSE}
#Binary: was reanalyzed or was not reanalyzed
model4 <- glm(data = latestAgiles, formula = reanalyzed ~ abcBuckets + sex + age + indication, family = binomial)

model4.red <- glm(data = latestAgiles, formula = reanalyzed ~ sex + age + indication, family = binomial)

nameOfOutput.4 <- "R2 or not with latest reports, abc"
```

```{r reclassmodel4, include=FALSE}
#Binary: was reclassified or was not reclassified
reclass41 <- glm(data = justReanaz, 
                 formula = Reclassified ~ abcBuckets + age + sex + indication,
                 family = binomial)

reclass42 <- glm(data = uniqueReanaz, 
                 formula = Reclassified ~ abcBuckets + age + sex + indication,
                 family = binomial)

reclass41.red <- glm(data = justReanaz, 
                     formula = Reclassified ~ age + sex + indication,
                     family = binomial)

reclass42.red <- glm(data = uniqueReanaz, 
                     formula = Reclassified ~ age + sex + indication,
                     family = binomial)


nameOfOutput.41 <- "reclass vs not with all R2, abc"
nameOfOutput.42 <- "reclass vs not with sampled R2, abc"
```

```{r gilesmodel5, include=FALSE}
#REA ABC buckets with confounders of cases with reported alterations binary is positive vs is uncertain (negatives removed)
outcomes51 <- glm(data = posUncertain, 
                  formula = classification ~ abcBuckets + age + sex + indication,
                  family = binomial)

outcomes52 <- glm(data = uniqueUncertain, 
                  formula = classification ~ abcBuckets + age + sex + indication,
                  family = binomial)

outcomes51.red <- glm(data = posUncertain, 
                      formula = classification ~ age + sex + indication,
                      family = binomial)

outcomes52.red <- glm(data = uniqueUncertain, 
                      formula = classification ~ age + sex + indication,
                      family = binomial)

nameOfOutput.51 <- "pos vs unc with all 1/0 reclass, abc"
nameOfOutput.52 <- "pos vs unc with sampled 1/0 reclass, abc"
```

```{r gilesmodel6, include=FALSE}
#REA Default buckets with confounders of cases with reported alterations binary is positive vs is uncertain (negatives removed)
outcomes61 <- glm(data = posUncertain, 
                  formula = classification ~ `Default.REA.buckets` + age + sex + indication,
                  family = binomial)

outcomes62 <- glm(data = uniqueUncertain, 
                  formula = classification ~ `Default.REA.buckets` + age + sex + indication,
                  family = binomial)

outcomes61.red <- glm(data = posUncertain, 
                      formula = classification ~ age + sex + indication,
                      family = binomial)

outcomes62.red <- glm(data = uniqueUncertain, 
                      formula = classification ~ age + sex + indication,
                      family = binomial)

nameOfOutput.61 <- "pos vs unc with all 1/0 reclass, defaults"
nameOfOutput.62 <- "pos vs unc with sampled 1/0 reclass, defaults"

```

```{r gilesmodel7, include=FALSE}
# REA Default buckets with confounders age/sex/(?indication) by:

# Additional polynomial analysis if there is time. Per our notes, these will need a random intersection score 
#   calculation (I think thatâ€™s what it was called) to account for the potential multiple reanalysis events in a single 
#   individual and randomly select one to be used in this analysis.
# Trigger for reanalysis (Ambry, Provider, Family studies) *This cohort will only include those who have had a reanalysis*

trigger7 <- multinom(data = uniqueReanaz, 
                     formula = `Initiator.of.reanalysis` ~ `Default.REA.buckets` + age + sex + indication)

trigger7.red <- multinom(data = uniqueReanaz, 
                         formula = `Initiator.of.reanalysis` ~ age + sex + indication)

nameOfOutput.7 <- "initiators with sampled R2, defaults"

```

```{r gilesmodel8, include=FALSE}
# Evidence used for reclassifications (gene, variant, clinical overlap) *This cohort will only include those who have had a reclassification*
evidence8 <- multinom(data = uniqueReclass, 
                      formula = `Evidence.for.reclassification` ~ `Default.REA.buckets` + age + sex + indication)

evidence8.red <- multinom(data = uniqueReclass, 
                          formula = `Evidence.for.reclassification` ~ age + sex + indication)

nameOfOutput.8 <- "evidence with sampled reclass, defaults"

```

```{r gilesmodel9, include=FALSE}
# Trigger for reanalysis (Ambry, Provider, Family studies) *This cohort will only include those who have had a reanalysis*
# REA ABC buckets with confounders age/sex/(?indication) by:

trigger9 <- multinom(data = uniqueReanaz, 
                     formula = `Initiator.of.reanalysis` ~ abcBuckets + age + sex + indication)

trigger9.red <- multinom(data = uniqueReanaz, 
                         formula = `Initiator.of.reanalysis` ~ age + sex + indication)

nameOfOutput.9 <- "initiators with sampled R2, abc"

```

```{r gilesmodel10, include=FALSE}
# Evidence used for reclassifications (gene, variant, clinical overlap) *This cohort will only include those who have had a reclassification*

evidence10 <- multinom(data = uniqueReclass, 
                       formula = `Evidence.for.reclassification` ~ abcBuckets + age + sex + indication)

evidence10.red <- multinom(data = uniqueReclass, 
                           formula = `Evidence.for.reclassification` ~ age + sex + indication)

nameOfOutput.10 <- "evidence with sampled reclass, abc"


```

```{r extra, include=FALSE}

# Run the likelihood ratio test #
# comparison between models with or without abcBuckets or Default REA buckets #

# H0: Both the full and nested models fit the data equally well. As a result, you should employ the nested model.
# 
# H1: The full model significantly outperforms the nested model in terms of data fit. As a result, you should use the entire model.
#   if the p-value is <0.05 then we reject the null hypothesis, concluding that the full model provides a better fit

lr.model1.1 <- lrtest(model1.1,model1.1.red)

lr.model1.2 <- lrtest(model1.2,model1.2.red)

lr.model2 <- lrtest(model2,model2.red)

lr.reclass21 <- lrtest(reclass21,reclass21.red)

lr.reclass22 <- lrtest(reclass22,reclass22.red)

lr.model3.1 <- lrtest(model3.1,model3.1.red)

lr.model3.2 <- lrtest(model3.2,model3.2.red)

lr.model4 <- lrtest(model4,model4.red)

lr.reclass41 <- lrtest(reclass41,reclass41.red)

lr.reclass42 <- lrtest(reclass42,reclass42.red)

lr.outcomes51 <- lrtest(outcomes51,outcomes51.red)

lr.outcomes52 <- lrtest(outcomes52,outcomes52.red)

lr.outcomes61 <- lrtest(outcomes61,outcomes61.red)

lr.outcomes62 <- lrtest(outcomes62,outcomes62.red)

lr.trigger7 <- lrtest(trigger7,trigger7.red)

lr.evidence8 <- lrtest(evidence8,evidence8.red)

lr.trigger9 <- lrtest(trigger9,trigger9.red)

lr.evidence10 <- lrtest(evidence10,evidence10.red)

lr.model1.1 # reject null

lr.model1.2 # reject null

# strongly reject null
listOfModels <- list(model1.1, # reject null
                  model1.2, # reject null
                  model2, # strongly reject null
                  reclass21, # barely reject null
                  reclass22, # barely reject null
                  model3.1, # fail to reject null
                  model3.2, # reject null
                  model4, # strongly reject null
                  reclass41, # barely fail to reject null
                  reclass42, # barely reject null
                  outcomes51, # fail to reject null
                  outcomes52, # fail to reject null
                  outcomes61, # fail to reject null
                  outcomes62, # fail to reject null
                  trigger7, # barely fail to reject null
                  evidence8, # fail to reject null
                  trigger9,# barely fail to reject null
                  evidence10) # fail to reject null

listOfLogModels <- list(model1.1, # reject null
                  model1.2, # reject null
                  model2, # strongly reject null
                  reclass21, # barely reject null
                  reclass22, # barely reject null
                  model3.1, # fail to reject null
                  model3.2, # reject null
                  model4, # strongly reject null
                  reclass41, # barely fail to reject null
                  reclass42, # barely reject null
                  outcomes51, # fail to reject null
                  outcomes52, # fail to reject null
                  outcomes61, # fail to reject null
                  outcomes62) # fail to reject null

listOfFormula <- sapply(listOfModels,FUN = function(model)(model$formula))
listOfFormula[15:18] <- "multinom"

listOfLRT <- list(lr.model1.1, # reject null
                  lr.model1.2, # reject null
                  lr.model2, # strongly reject null
                  lr.reclass21, # barely reject null
                  lr.reclass22, # barely reject null
                  lr.model3.1, # fail to reject null
                  lr.model3.2, # reject null
                  lr.model4, # strongly reject null
                  lr.reclass41, # barely fail to reject null
                  lr.reclass42, # barely reject null
                  lr.outcomes51, # fail to reject null
                  lr.outcomes52, # fail to reject null
                  lr.outcomes61, # fail to reject null
                  lr.outcomes62, # fail to reject null
                  lr.trigger7, # barely fail to reject null
                  lr.evidence8, # fail to reject null
                  lr.trigger9,# barely fail to reject null
                  lr.evidence10) # fail to reject null


listOfChiSqP <- sapply(listOfLRT,FUN = function(lrtmodel)(lrtmodel$`Pr(>Chisq)`[2][1]),simplify = F)
listOfChiSq <- sapply(listOfLRT,FUN = function(lrtmodel)(lrtmodel$Chisq[2][1]),simplify = F)

listOfLRTnames <- c("lr.model1.1", # reject null
                          "lr.model1.2", # reject null
                          "lr.model2", # strongly reject null
                          "lr.reclass21", # barely reject null
                          "lr.reclass22", # barely reject null
                          "lr.model3.1", # fail to reject null
                          "lr.model3.2", # reject null
                          "lr.model4", # strongly reject null
                          "lr.reclass41", # barely fail to reject null
                          "lr.reclass42", # barely reject null
                          "lr.outcomes51", # fail to reject null
                          "lr.outcomes52", # fail to reject null
                          "lr.outcomes61", # fail to reject null
                          "lr.outcomes62", # fail to reject null
                          'lr.trigger7', # barely fail to reject null
                          'lr.evidence8', # fail to reject null
                          "lr.trigger9",# barely fail to reject null
                          "lr.evidence10") # fail to reject null

listOfModelDesc <- c(nameOfOutput.11,
                     nameOfOutput.12,
                     nameOfOutput.2,
                     nameOfOutput.21,
                     nameOfOutput.22,
                     nameOfOutput.31,
                     nameOfOutput.32,
                     nameOfOutput.4,
                     nameOfOutput.41,
                     nameOfOutput.42,
                     nameOfOutput.51,
                     nameOfOutput.52,
                     nameOfOutput.61,
                     nameOfOutput.62,
                     nameOfOutput.7,
                     nameOfOutput.8,
                     nameOfOutput.9,
                     nameOfOutput.10)

plotFrame <- tibble(names = unlist(listOfLRTnames),
                    LRTpv = unlist(listOfChiSqP),
                    formula = unlist(listOfFormula),
                    desc = listOfModelDesc)
plotFrame <- arrange(plotFrame, LRTpv)
modelGroups <- c("default","abc","default",
                 "default","abc","abc",
                 "default","default","default",
                 "abc","abc","abc",
                 "abc","abc","default",
                 "default","abc","default")
plotFrame <- mutate(plotFrame, groupNames = modelGroups)

```


```{r plot1, include=FALSE}
# needs so much fine tuning
descPlot <- ggplot(plotFrame, aes(x=reorder(desc,LRTpv), y=sort(LRTpv))) +
  geom_segment(aes(x=reorder(desc,LRTpv), xend=reorder(desc,LRTpv), y=0.05, yend=LRTpv), color="grey") +
  geom_point(aes(color=groupNames), size=4) +
  geom_hline(yintercept=0.05, color = "red") +
  theme_light() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(angle = 75, hjust=1,size = rel(1.05))
  ) +
  xlab("") +
  ylab("LRT p-value")

# ggplot(plotFrame, aes(x=reorder(names,LRTpv), y=sort(LRTpv))) +
#   geom_segment(aes(x=reorder(names,LRTpv), xend=reorder(names,LRTpv), y=0.05, yend=LRTpv), color="grey") +
#   geom_point(aes(color=groupNames), size=4) +
#   geom_hline(yintercept=0.05, color = "red") +
#   theme_light() +
#   theme(
#     panel.grid.major.x = element_blank(),
#     panel.border = element_blank(),
#     axis.ticks.x = element_blank(),
#     axis.text.x = element_text(angle = 75, hjust=1,size = rel(1.05))
#   ) +
#   xlab("") +
#   ylab("LRT p-value")


```

```{r binnedResid, include = FALSE}
# needs binned residual
plot(model3.1,which=1)
arm::binnedplot(x = predict(model3.1), y = resid(model3.1), 
           main = paste("Binned residual plot",
                        deparse(substitute(model3.1))))

listOfLogModels <- listOfModels[1:14]

sapply(listOfLogModels, FUN = function(model)(
  arm::binnedplot(x = predict(model), y = resid(model), 
                  main = paste("Binned residual plot: \n",
                               c(model$call[1:3]),
                               "\n",
                               tail(model$call, 1),
                               collapse = ' '))),simplify = F)

binnResid <- function(model){
  arm::binnedplot(x = predict(model), y = resid(model), 
                  main = paste("Binned residual plot: \n",
                               c(model$call[1:3]),
                               "\n",
                               tail(model$call, 1),
                               collapse = ' '))
}

```

```{r exploreInteraction, include = FALSE}
outcomesINT <- glm(data = uniqueUncertain, 
                  formula = classification ~ abcBuckets*indication + sex + age ,
                  family = binomial)
outcomesINT.red <- glm(data = uniqueUncertain, 
                  formula = classification ~ sex + age + indication,
                  family = binomial)

lr.INT <- lrtest(outcomesINT,outcomesINT.red)
binnResid(outcomesINT)
binnResid(outcomes52)
see <- data.frame(uniqueUncertain,predict(outcomesINT))


```

```{r reportTODO, include = FALSE}

# multinomial binned residuals
# explanation
# other figures/plots
# another table?

```

# EXOMES and REA Model Report

## Study Aims

-   To compare the report outcomes on initial exome reports between REA groups
-   To compare reclassification rates and outcomes between REA groups
-   To compare reclassification evidence types used between REA groups

## Proportional Analysis and EDA

```{r propCode, include = FALSE}
propTableOg <- spread(dplyr::select(newOg,-n),classification, prob)
propTableOg2 <- spread(dplyr::select(newOg,-prob),classification, n)
propTable <- spread(dplyr::select(newLatest,-n),classification, prob)
propTable2 <- spread(dplyr::select(newLatest,-prob),classification, n)
```

Proportion between REA and classification, original reports
```{r proportion tables1}
propTableOg
```

```{r proportion tables2}
propTableOg2
```

Proportion between REA and classification, latest reports
```{r proportion tables3}
propTable
```

```{r proportion tables4}
propTable2
```

```{r reanazMean}

reanazGG

```

```{r reclassMean}

reclassGG

```

## Analysis

In order to explore how REA impacts exome reporting, this study will build logistic and multinomial models using abc and default REA buckets as predictors to determine how an exome may be classified, whether an exome is reanalyzed or reclassified, how a reanalysis is initiated, and the evidence used to make a reclassification.  Including sex, age, and indication as possible confounders. 

To statistically evaluate the impact of REA on exome reporting, this study has deployed the likelihood ratio test. 
The likelihood ratio test, in summary, compares how well two models fit by using the ratio of their likelihoods.
In this case there is some probability that a given exome will be evaluated in some fashion based on the age, sex, and indication of the patient based on the data.  Calculating the probability of how an exome will be evaluated including the patient REA, the test, assuming a null hypothesis that REA has no effect on exome evaluation, compares the estimated probabilities.  If the test statistic falls below the threshold the null hypothesis is rejected and REA is significant to exome evaluation.

- Models, where the null was rejected (p\<=0.05), indicate that abcBuckets/defaults are significant and should be included 
- Models, failing to reject the null (p\>0.05), indicate that abcBuckets/defaults are not significant and the simple model is preferred.  These are cases where we are not observing significant variation between REA factors.

Below is a comparison of the constructed models and their likelihood ratio test statistic.  Models below the threshold reject the null hypothesis, indicating REA significance, the others fail to do so.
```{r LRTPvalPlot}
descPlot
```

A table describing the models and listing their test statistic.
```{r modelsFailReject}
plotFrame
```

### Model Details

As the purpose of these models is inferential and not predictive, they generally do not deliver meaningful predication.  Models will use the most significant factor of each variable as its (Intercept)/baseline, modifying the estimate accordingly for other factors. The reader can still evaluate the significance of each factor by comparing the magnitude of their estimates, standard error, and p-value.

For example:

```{r exMod, echo=TRUE}
exMod <- glm(data = originals, formula = classification ~ abcBuckets, family = binomial)
summary(exMod)
```
- (Intercept) here refers to the estimate about abcBucket A, forming the basis for the other estimates which each modify the intercept accordingly.
- Compare the estimates for abcBucket C and abcBucket B: although the estimate for C is larger than the estimate for B, it has a larger standard error resulting in a higher p-value and a lower significance. A low p-value indicates that the factor is likely non-zero and does explain the result, a high p-value means it is not possible to conclude the factor affects the output in this sample.

Likelihood Ratio Test example:

```{r exLRT}
exMod <- glm(data = originals, formula = classification ~ indication + abcBuckets, family = binomial)
exMod.red <- glm(data = originals, formula = classification ~ abcBuckets, family = binomial)

lrtest(exMod,exMod.red)
```
This LRT is comparing a model including indication and REA, with the example model from above. The returned `Pr(>Chisq)`(p-value) indicated that the test null hypothesis, indication is not a meaningful predictor, should be rejected.  In this example we prefer the updated model as it more accurately estimates an exome's classification.

Example Binned Residual Plot

```{r}
binnResid(exMod)
```
A binned residual plot splits the data into bins, whereupon the average fitted value in each bin is compared with the bin's average errors. As with most residual plots an adequate model fit should produce random, noisy residuals representative of normal sample noise: The reader should be mindful about interpreting models with residual plots that do not adhere to this chaotic standard.  This could include patterns in residuals, extreme outliers or other orderly aberrations.

### Binary Models

#### `r nameOfOutput.11`

```{r model1.1, echo=TRUE}

summary(model1.1)

```

```{r lr.model1.1, echo=TRUE}

lr.model1.1

```

```{r resid, echo=FALSE}

binnResid(model1.1)

```

#### `r nameOfOutput.12`

```{r model1.2, echo=TRUE}

summary(model1.2)

```

```{r lr.model1.2, echo=TRUE}

lr.model1.2

```

```{r resid2, echo=FALSE}

binnResid(model1.2)

```

#### `r nameOfOutput.31`

```{r model3.1, echo=TRUE}

summary(model3.1)

```

```{r lr.model3.1, echo=TRUE}

lr.model3.1

```

```{r resid3, echo=FALSE}

binnResid(model3.1)

```

#### `r nameOfOutput.32`

```{r model3.2, echo=TRUE}

summary(model3.2)

```

```{r lr.model3.2, echo=TRUE}

lr.model3.2

```

```{r resid4, echo=FALSE}

binnResid(model3.2)

```

#### `r nameOfOutput.2`

```{r model2, echo=TRUE}

summary(model2)

```

```{r lr.model2, echo=TRUE}

lr.model2

```

```{r resid5, echo=FALSE}

binnResid(model2)

```

#### `r nameOfOutput.4`

```{r model4, echo=TRUE}

summary(model4)

```

```{r lr.model4, echo=TRUE}

lr.model4

```

```{r resid6, echo=FALSE}

binnResid(model4)

```

#### `r nameOfOutput.22`

```{r reclass22, echo=TRUE}

summary(reclass22)

```

```{r lr.reclass22, echo=TRUE}

lr.reclass22

```

```{r resid7, echo=FALSE}

binnResid(reclass22)

```

#### `r nameOfOutput.42`

```{r reclass42, echo=TRUE}

summary(reclass42)

```

```{r lr.reclass42, echo=TRUE}

lr.reclass42

```

```{r resid8, echo=FALSE}

binnResid(reclass42)

```

#### `r nameOfOutput.52`

```{r outcomes52, echo=TRUE}

summary(outcomes52)

```

```{r lr.outcomes52, echo=TRUE}

lr.outcomes52

```

```{r resid9, echo=FALSE}

binnResid(outcomes52)

```

#### `r nameOfOutput.62`

```{r outcomes62, echo=TRUE}

summary(outcomes62)

```

```{r lr.outcomes62, echo=TRUE}

lr.outcomes62

```

```{r resid10, echo=FALSE}

binnResid(outcomes62)

```

### Multinomial Models about Evidence and Initiators

Multinomial models have more than 2 outcome categories.  The result displays coefficient estimates for each predictor for each output category.  In lieu of p-value and standard errors in the model summary the reader is left to evaluate the significance of each estimate via comparison with other estimates.  The LRT output remains consistent and null hypothesis can still be considered.

#### `r nameOfOutput.7`

```{r trigger7, echo=TRUE}

summary(trigger7)

```

```{r lr.trigger7, echo=TRUE}

lr.trigger7

```

#### `r nameOfOutput.9`

```{r trigger9, echo=TRUE}

summary(trigger9)

```

```{r lr.trigger9, echo=TRUE}

lr.trigger9

```

#### `r nameOfOutput.8`

```{r evidence8, echo=TRUE}

summary(evidence8)

```

```{r lr.evidence8, echo=TRUE}

lr.evidence8

```

#### `r nameOfOutput.10`

```{r evidence10, echo=TRUE}

summary(evidence10)

```

```{r lr.evidence10, echo=TRUE}

lr.evidence10

```


### Notes
Additional analysis might consider the interaction between indication and REA, some testing showed REA significance increase when indication was interacted with.
The author is working out how to generate binned residual plots about multinomial models. Those will be available for consideration in the final report. 

```{r include = FALSE}
# notes about what to do,
#  questions about the models,
#    and more

# 1) could we run a fischer test comparing individual buckets to the other ones?
# 2) signifiy which buckets matter/ which buckets matter more/less?
# 3) Can we compare stat significance between groups B anbd C 
# 4) 


```